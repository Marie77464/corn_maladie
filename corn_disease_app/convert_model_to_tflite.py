"""
Script pour convertir un modÃ¨le TensorFlow en TensorFlow Lite
Pour l'application de dÃ©tection de maladies du maÃ¯s
"""

import tensorflow as tf
import numpy as np

def convert_model_to_tflite(model_path, output_path='corn_disease_model.tflite'):
    """
    Convertit un modÃ¨le TensorFlow (.h5 ou SavedModel) en TensorFlow Lite
    
    Args:
        model_path: Chemin vers ton modÃ¨le (.h5 ou dossier SavedModel)
        output_path: Nom du fichier .tflite de sortie
    """
    
    print("ğŸ”„ Chargement du modÃ¨le...")
    # Charger le modÃ¨le
    model = tf.keras.models.load_model(model_path)
    
    print("ğŸ“Š Architecture du modÃ¨le:")
    model.summary()
    
    # CrÃ©er le convertisseur
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # Options d'optimisation pour rÃ©duire la taille
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    
    print("âš™ï¸ Conversion en cours...")
    tflite_model = converter.convert()
    
    # Sauvegarder le modÃ¨le TFLite
    with open(output_path, 'wb') as f:
        f.write(tflite_model)
    
    # Afficher la taille du fichier
    import os
    size_mb = os.path.getsize(output_path) / (1024 * 1024)
    print(f"âœ… ModÃ¨le converti avec succÃ¨s!")
    print(f"ğŸ“ Fichier: {output_path}")
    print(f"ğŸ’¾ Taille: {size_mb:.2f} MB")
    
    # Tester le modÃ¨le TFLite
    print("\nğŸ§ª Test du modÃ¨le TFLite...")
    test_tflite_model(output_path)

def test_tflite_model(tflite_path):
    """
    Teste le modÃ¨le TFLite avec une image alÃ©atoire
    """
    # Charger le modÃ¨le TFLite
    interpreter = tf.lite.Interpreter(model_path=tflite_path)
    interpreter.allocate_tensors()
    
    # Obtenir les dÃ©tails d'entrÃ©e et de sortie
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"ğŸ“¥ Input shape: {input_details[0]['shape']}")
    print(f"ğŸ“¤ Output shape: {output_details[0]['shape']}")
    
    # CrÃ©er une image de test (224x224x3)
    test_image = np.random.rand(1, 224, 224, 3).astype(np.float32)
    
    # Faire une prÃ©diction test
    interpreter.set_tensor(input_details[0]['index'], test_image)
    interpreter.invoke()
    output_data = interpreter.get_tensor(output_details[0]['index'])
    
    classes = ['Blight', 'Common_Rust', 'Gray_Leaf_Spot', 'Healthy']
    predicted_class = np.argmax(output_data[0])
    confidence = output_data[0][predicted_class] * 100
    
    print(f"ğŸ¯ Test rÃ©ussi!")
    print(f"   Classe prÃ©dite: {classes[predicted_class]}")
    print(f"   Confiance: {confidence:.2f}%")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸŒ½ CONVERTISSEUR DE MODÃˆLE - DÃ©tection Maladies MaÃ¯s")
    print("=" * 60)
    
    # REMPLACE CE CHEMIN PAR LE CHEMIN VERS TON MODÃˆLE
    # Exemples:
    # - Si tu as un fichier .h5: model_path = "mon_modele.h5"
    # - Si tu as un dossier SavedModel: model_path = "mon_modele_dossier/"
    
    model_path = input("\nğŸ“‚ Entre le chemin vers ton modÃ¨le (.h5 ou SavedModel): ").strip()
    
    try:
        convert_model_to_tflite(model_path)
        print("\nâœ… Conversion terminÃ©e! Tu peux maintenant utiliser le fichier .tflite dans ton app.")
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        print("\nğŸ’¡ Assure-toi que:")
        print("   - Le chemin vers ton modÃ¨le est correct")
        print("   - TensorFlow est installÃ©: pip install tensorflow")
